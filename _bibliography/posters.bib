---
---
@misc{Chen2022Covid,
    author = {Chen, Caitlin K. and Ford, Kassidy M. and Wong, Leela M. and Zhao, Eric L. and Huang, William and Eisenberg, Daniel},
    title = {Differences in Drug and Alcohol Consumption Among College Students During the COVID-19 Pandemic},
    year = {2022},
    booktitle = {2022 UCLA Undergraduate Research Week},
    pdf = {publications/chen2022covid.pdf}
}

@misc{Huang2023UIW,
    author = {Huang, William and Ghahremani, Sam, and Pei, Siyou, and Zhang, Yang},
    title = {Users in Wheelchairs (UIW) - A Human Centered RGB Dataset of Wheelchair Users},
    year = {2023},
    booktitle={UCLA Summer Undergraduate Research Program Research Journal},
    pdf = {publications/huang2023uiw.pdf},
    abstract = {Kinematic analysis of the human body has become an integral tool in multiple fields spanning from
    sports performance, rehabilitation, animations, and physical modeling. While traditional marker-based
    solutions are commonly used in kinematic analysis, it is not suitable for “in field” tasks. This problem is
    further exacerbated in users with disabilities, who may face difficulties in data collection settings.
    Markerless video-based motion capture systems using deep learning to estimate the poses of users
    through camera images, offering a more accessible alternative. These systems rely on large amounts of
    image data of humans in different day to day actions. However, most commonly available markerless
    motion capture systems including MediaPipe, OpenPose, BlazePose, and Detectron2 are purely trained
    off able-bodied datasets like COCO and consequently perform worse on users in wheelchairs. To address
    this disparity, we present Users in Wheelchairs (UIW), a new dataset focused on wheelchair users. This is
    achieved by collecting data on common and extreme wheelchair related activities which are then placed
    in the context of real-world settings through manual video capture. Over 2.5k images were collected
    from 20 hours of video of wheelchair users in 21 different action classes from novel data collection
    software designed to capture and label video frames. Each instance's keypoints were then labeled
    through crowd worker involvement. We provide statistical analysis on our dataset in comparison to the
    COCO dataset and found a 32.50 AP improvement in bounding boxes on users in wheelchairs and a 13.34
    AP improvement in keypoint precision.}
}

@misc{Huang2020algae,
    author = {Huang, William},
    title = {Sugar versus plant fertilizer to encourage the growth of microalgae},
    year = {2020},
    booktitle = {Orange County Beckman Legacy Award},
    html = {https://www.beckman-foundation.org/people/william-huang/}
}
